---
title: "p8105_hw2_zw2974"
author: "Zihan Wu"
date: "9/27/2023"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(dplyr)
library(readxl)
```


## Problem 1

We clean the 538 `pols` data, which provides information on the number of national politicians who are democratic or republican at any given time. There are some values for which `prez_gop` is `2` -- these are months in which Ford became President following Nixon's resignation. In the new `president` variable created as part of our data cleaning, we code these as `gop` (same as values when `prez_gop` is `1`).

```{r clean_538_pols}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("data/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

We also clean the 538 `snp` data, which contains information related to Standard & Poorâ€™s stock market index.

```{r clean_538_snp}
snp = 
  read_csv("data/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(month_df) |> 
  select(year, month, close) 
```

Finally, we tidy the `unemployment` data so that it can be merged with the `pols` and `snp` datasets.

```{r clean_538_unemp}
unemployment = 
  read_csv("data/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(month_df) |> 
  select(year, month, unemployment)
```

Now we merge the three datasets!

```{r merge_538}
data_538 = 
  left_join(pols, snp) |>
  left_join(y = unemployment)

str(data_538)
```

Notice that there are some `NA` values in the `close` and `unemployment` variables, which indicate that the value of these variables is missing at those locations.

Let's talk about the 538 datasets. The `pols` data has `r nrow(pols)` observations and `r ncol(pols)` variables and tells us about the party affiliation distribution (democrat or republican) for governors and senators for a given year from years `r pols |> pull(year) |> min()` to `r pols |> pull(year) |> max()`. It also tells us whether the sitting president was a democrat or republican. The `snp` data has `r nrow(snp)` observations and `r ncol(snp)` variables, ranging from years `r snp |> pull(year) |> min()` to `r snp |> pull(year) |> max()`. The `unemployment` data has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables ranging from years `r unemployment |> pull(year) |> min()` to `r unemployment |> pull(year) |> max()`. In Januarys in or after 1975 in which a democrat was president, the **average unemployment rate was `r filter(data_538, month == "January", year >= 1975, president == "dem") |> pull(unemployment) |> mean() |> round(2)`**.  The average unemployment rate over the same time period in which a republican was president was `r filter(data_538, month == "January", year >= 1975, president == "gop") |> pull(unemployment) |> mean() |> round(2)`.


# Problem 2

## Read and clean the Mr. Trash Wheel sheet:

```{r}
mr_trash_wheel = read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N586") |> 
  janitor::clean_names() |> 
  mutate(homes_powered = weight_tons * 500 /30) |> 
  mutate(type = "Mr.") |> 
  mutate(year = as.integer(year)) |> 
  drop_na(dumpster)
```

## Read and clean the Professor Trash Wheel sheet:

```{r}
professor_df = read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M108") |> 
  janitor::clean_names() |> 
  mutate(homes_powered = weight_tons * 500 /30) |> 
  mutate(type = "Professor") |> 
  mutate(year = as.integer(year)) |> 
  drop_na(dumpster)

```

## Read and clean the Gwynnda Trash Wheel sheet:

```{r}
gwynnda_df = read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L157") |> 
  janitor::clean_names() |> 
  mutate(homes_powered = weight_tons * 500 /30) |>
  mutate(type = "Gwynnda") |> 
  mutate(year = as.integer(year)) |>
  drop_na(dumpster)
```

## Combine:

```{r}
combination = bind_rows(mr_trash_wheel, professor_df, gwynnda_df) |> 
  relocate(type)

combination
```

## Write a paragraph about these data:

Number of observations: `r nrow(combination)`

Numbers of variables: `r ncol(combination)`

Names of key variables: `r names(combination)`

Total weight of trash collected by Professor Trash Wheel: `r sum(professor_df$weight_tons)`

Total number of cigarette butts collected by Gwynnda in July of 2021: `r sum(gwynnda_df$cigarette_butts[which(gwynnda_df$month == "July" & gwynnda_df$year == 2021)])`

# Problem 3

## Import, clean, and tidy the dataset of baseline demographics
* sex and APOE4 carrier status are appropriate encoded (i.e. not numeric)
* remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline)

```{r}
baseline = read_csv("data/MCI_baseline.csv", skip = 1) |> 
  janitor::clean_names() |> 
  mutate(
    sex = case_match(
      sex,
      1 ~ "Male",
      0 ~ "Female")
    ) |> 
  mutate(
    apoe4 = case_match(
      apoe4,
      1 ~ "APOE4 carrier",
      0 ~ "APOE4 non-carrier")
    )
baseline_df = baseline |> 
  filter(age_at_onset != ".")
```

## Discuss important steps in the import process and relevant features of the dataset

`r nrow(baseline)` participants were recruited

`r nrow(baseline_df)` participants develop MCI

```{r,echo=FALSE}
avg_age = baseline_df |> 
  summarise(mean_age = mean(current_age, na.rm = T)) |> 
  pull(mean_age)
```

Average baseline age: `r avg_age`

```{r}
woman_APOE4 = baseline_df |> 
  filter(sex == "Female" & apoe4 == "APOE4 carrier") |> 
  count()
```

Proportion of women in the study are APOE4 carriers: `r woman_APOE4/nrow(baseline_df)`

## Import, clean, and tidy the dataset of longitudinally observed biomarker values

```{r}
amyloid = read_csv("data/mci_amyloid.csv", skip = 1) |> 
  janitor::clean_names() |> 
  subset(
    baseline != "NA" & baseline != "Na"
  ) |> 
  rename(
    id = study_id
  )
amyloid
```

## Comment on the steps on the import process and the features of the dataset

Data imported from `mci_amyloid.csv` and participants who have no MCI would be eliminated from baseline column. `study_id` changed name for better understanding.

`r nrow(read_csv("data/mci_amyloid.csv",skip = 1))` participants were recruited.

`r nrow(amyloid)` participants observed biomarker values.

## Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings

```{r, echo = F}
merge_df = left_join(baseline_df, amyloid, by = "id")

baseline_only = merge_df |> 
  subset(
    is.na(merge_df$baseline)
  )
baseline_only
```

There are `r nrow(baseline_only)` participants appear in only the baseline datasets. 

```{r, echo = F}
merge_df2 =
  right_join(baseline_df, amyloid, by = "id")

amyloid_only=
  merge_df2|>
  subset(
    is.na(merge_df2$age_at_onset))
```

There are `r nrow(amyloid_only)` participants appear in only the amyloid datasets.

## Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset

```{r,echo=FALSE}
both =
  inner_join(baseline_df, amyloid, by="id")

complete =  
  both |> 
  na.omit(both)
```

From the dataset, we can discover there are `r nrow(both)` participants while only `r nrow(complete)` can accomplish the process

## Export the result as a CSV to your data directory
```{r}
write_csv(both,"Both mci_baseline and mci_amyloid")
write_csv(complete,"Complete participants")
```
